{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLD1G_FH9AbF",
        "outputId": "6b587f2d-a3d3-4fb9-c47e-050549e4fc76"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: rdkit in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (2024.9.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from rdkit) (11.1.0)\n",
            "Requirement already satisfied: torch-geometric in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (3.11.13)\n",
            "Requirement already satisfied: fsspec in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (2025.2.0)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (3.1.5)\n",
            "Requirement already satisfied: numpy in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (5.9.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (3.2.0)\n",
            "Requirement already satisfied: requests in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (2.4.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from requests->torch-geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: colorama in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
            "Requirement already satisfied: deap in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy in c:\\users\\karim\\anaconda3\\envs\\eos\\lib\\site-packages (from deap) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install rdkit\n",
        "!pip install torch-geometric\n",
        "!pip install deap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hbP6k6GZ9kPK"
      },
      "outputs": [],
      "source": [
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw, Descriptors\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch_geometric.data import Data\n",
        "import torch_geometric.utils as pyg_utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from deap import base, tools, creator, algorithms\n",
        "import copy\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ib1qXopX8rwO"
      },
      "outputs": [],
      "source": [
        "# data cols\n",
        "# ['sci_name','name','cid','smile','Molecular Weight','LogP','TPSA','Rotatable Bonds','H Bond Donors','H Bond Acceptors','Aromatic Rings','Num Rings','Atom Count','coulomb_matrix','embeddings']\n",
        "\n",
        "class MoleculeVisualizer():\n",
        "\n",
        "    def visualize_molecule_2D(self, smiles):\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        mol = Chem.AddHs(mol) # add implicit hydrogens\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES string.\")\n",
        "            return\n",
        "\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        return img\n",
        "\n",
        "class MoleculeGraphConverter():\n",
        "    \"\"\"Converts SMILES strings to PyTorch Geometric graph representations.\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def smiles_to_graph(smiles):\n",
        "        \"\"\"Convert a SMILES string into a graph representation.\"\"\"\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            return None  # Handle invalid molecules\n",
        "\n",
        "        num_atoms = mol.GetNumAtoms()\n",
        "\n",
        "        # Node features: Atomic number\n",
        "        node_feats = torch.tensor([atom.GetAtomicNum() for atom in mol.GetAtoms()], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        # Edge indices and features\n",
        "        edge_indices, edge_attrs = [], []\n",
        "        for bond in mol.GetBonds():\n",
        "            start, end = bond.GetBeginAtomIdx(), bond.GetEndAtomIdx()\n",
        "            edge_indices.append((start, end))\n",
        "            edge_indices.append((end, start))  # Bidirectional edges\n",
        "\n",
        "            bond_type = bond.GetBondType()\n",
        "            edge_attrs.append(float(bond_type))\n",
        "            edge_attrs.append(float(bond_type))  # Bidirectional edges\n",
        "\n",
        "        if edge_indices:\n",
        "            edge_index = torch.tensor(edge_indices, dtype=torch.long).t().contiguous()\n",
        "            edge_attr = torch.tensor(edge_attrs, dtype=torch.float).view(-1, 1)\n",
        "        else:\n",
        "            edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "            edge_attr = torch.empty((0, 1), dtype=torch.float)\n",
        "\n",
        "        return Data(x=node_feats, edge_index=edge_index, edge_attr=edge_attr, num_nodes=num_atoms)\n",
        "\n",
        "    @staticmethod\n",
        "    def test_smiles_to_graph(self, dataset):\n",
        "        \"\"\"\n",
        "        Tests SMILES to graph conversion for all molecules in the dataset.\n",
        "        \"\"\"\n",
        "        errors = []\n",
        "        for i, smiles in enumerate(dataset.smiles):\n",
        "            try:\n",
        "                graph = self.smiles_to_graph(smiles)\n",
        "                if graph is None:\n",
        "                    errors.append((i, smiles, \"Graph conversion returned None\"))\n",
        "            except Exception as e:\n",
        "                errors.append((i, smiles, str(e)))\n",
        "\n",
        "        if errors:\n",
        "            print(f\"\\n{len(errors)} errors found in SMILES conversion:\\n\")\n",
        "            for err in errors:\n",
        "                print(f\"Index {err[0]}: {err[1]} -> {err[2]}\")\n",
        "        else:\n",
        "            print(\"All SMILES converted successfully!\")\n",
        "\n",
        "\n",
        "class EOS_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, scale=True, train=True):\n",
        "\n",
        "        self.imgs, self.y, self.smiles = self.load_data(train)\n",
        "        self.y = self.y.values.astype(np.float32)\n",
        "\n",
        "        transform_train = transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            transforms.RandomApply([transforms.RandomRotation(10)], p=0.5),\n",
        "            transforms.RandomApply([transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))], p=0.5),\n",
        "            transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
        "            transforms.RandomApply([transforms.RandomErasing(p=0.5, scale=(0.02, 0.1))], p=0.3),\n",
        "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "        transform_test = transforms.Compose([\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "        ])\n",
        "\n",
        "        self.transform = transform_train if train else transform_test\n",
        "\n",
        "        # if k_augs:\n",
        "        #     assert k_augs > 0\n",
        "        #     self.imgs, self.y = self.data_aug(k_augs)\n",
        "\n",
        "        # Separate scalers for a and b\n",
        "        self.scaler_a = StandardScaler()\n",
        "        self.scaler_b = StandardScaler()\n",
        "\n",
        "        # Fit scalers on the respective columns\n",
        "        if scale:\n",
        "          self.y[:, 0] = self.scaler_a.fit_transform(self.y[:, 0].reshape(-1, 1)).reshape(-1)\n",
        "          self.y[:, 1] = self.scaler_b.fit_transform(self.y[:, 1].reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "    def load_data(self, train):\n",
        "        urls = ['https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/test_data.csv',\n",
        "                'https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/train_data.csv']\n",
        "        url = urls[int(train)]\n",
        "\n",
        "        imgs = []\n",
        "\n",
        "        data = pd.read_csv(url)\n",
        "\n",
        "        X_cols = ['smile']\n",
        "        y_cols = ['a', 'b']\n",
        "\n",
        "        X = data[X_cols].copy()\n",
        "        y = data[y_cols]\n",
        "\n",
        "        # Ensure the first row is not a header issue\n",
        "        X = X.reset_index(drop=True)\n",
        "\n",
        "        for smile in X['smile']:\n",
        "            img = MoleculeVisualizer().visualize_molecule_2D(smile)\n",
        "            imgs.append(np.array(img, dtype=np.float32))\n",
        "        imgs = np.array(imgs, dtype=np.uint8)\n",
        "\n",
        "        return imgs, y, X['smile']\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = self.imgs[idx]\n",
        "        label = self.y[idx]\n",
        "\n",
        "        img = self.transform(img)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def transform(self, img):\n",
        "        return self.transform(img)\n",
        "\n",
        "    def inverse_transform(self, labels):\n",
        "        labels_unscaled = np.zeros_like(labels)\n",
        "        labels_unscaled[:, 0] = self.scaler_a.inverse_transform(labels[:,0].reshape(-1,1)).reshape(-1)\n",
        "        labels_unscaled[:, 1] = self.scaler_b.inverse_transform(labels[:,1].reshape(-1,1)).reshape(-1)\n",
        "        return labels_unscaled\n",
        "\n",
        "    # def data_aug(self, k_augs):\n",
        "\n",
        "    #     aug_imgs = np.repeat(self.imgs, k_augs, axis=0)\n",
        "    #     factor_y = np.repeat(self.y, k_augs, axis=0)\n",
        "\n",
        "    #     transform = transforms.Compose([\n",
        "\n",
        "    #     ])\n",
        "\n",
        "    #     for i, img in enumerate(aug_imgs):\n",
        "    #         img = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
        "    #         if i % k_augs == 0:\n",
        "    #             c_img = img\n",
        "    #         else:\n",
        "    #             c_img = transform(img)\n",
        "    #         c_img = c_img.permute(1, 2, 0).numpy()\n",
        "    #         aug_imgs[i] = c_img\n",
        "    #     return aug_imgs, factor_y\n",
        "\n",
        "class EOS_Dataloader():\n",
        "\n",
        "    def __init__(self, train, test):\n",
        "        self.train_loader = DataLoader(train, batch_size=32, shuffle=True)\n",
        "        self.test_loader = DataLoader(test, batch_size=32, shuffle=False)\n",
        "        self.train_smiles = train.smiles\n",
        "        self.test_smiles = test.smiles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "4P0SVLFj9M4m"
      },
      "outputs": [],
      "source": [
        "# combine with train script and add validation\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, dataloader, input_dim):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        self.cnn_pipeline = nn.Sequential( # consider affine=True\n",
        "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(16, affine=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (150,150)\n",
        "\n",
        "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32, affine=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (75x75)\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64, affine=False),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2), # (37x37)\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128, affine=False),\n",
        "            nn.ReLU(),\n",
        "            nn.AdaptiveAvgPool2d((1,1,)),\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            dummy_input = torch.zeros((1, 3, input_dim, input_dim), dtype=torch.float32)\n",
        "            dummy_output = self.cnn_pipeline(dummy_input)\n",
        "            flatten_size = dummy_output.view(1,-1).shape[1]\n",
        "\n",
        "        self.fc_pipeline = nn.Sequential(\n",
        "            nn.Linear(flatten_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(128, 64), \n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(64, 2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, predict=False):\n",
        "        x = self.cnn_pipeline(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc_pipeline(x)\n",
        "        if predict:\n",
        "            x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def weighted_loss(self, outputs, labels):\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "        loss = criterion(outputs, labels)\n",
        "        weight = torch.tensor([1.0, 80], device=device)  # Adjust if needed\n",
        "        return (loss * weight).mean()\n",
        "\n",
        "    def train_model(self, epochs=100, learning_rate=0.0001, patience=10, min_delta=0.001):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
        "\n",
        "        self.to(device)  # Move the model to GPU if available\n",
        "\n",
        "        loss_history = []\n",
        "        val_history = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_weights = None\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            running_val = 0.0\n",
        "\n",
        "            for data in self.dataloader.train_loader:\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(inputs, predict=True)\n",
        "                loss = self.weighted_loss(outputs, labels)\n",
        "                loss_history.append(loss.item())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                val_loss = self.train_val()\n",
        "                val_history.append(val_loss.item())\n",
        "                running_val += val_loss.item()\n",
        "\n",
        "            avg_val_loss = running_val / len(self.dataloader.test_loader)\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {running_loss / len(self.dataloader.train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "            print(f\"\\tValidation Loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "            # Early Stopping Logic\n",
        "            if avg_val_loss < best_val_loss - min_delta:\n",
        "                best_val_loss = avg_val_loss\n",
        "                best_model_weights = self.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "                break\n",
        "\n",
        "        # Restore best model before returning\n",
        "        if best_model_weights:\n",
        "            self.load_state_dict(best_model_weights)\n",
        "            print(\"Restored best model weights.\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(loss_history, label='Training Loss')\n",
        "        plt.plot(val_history, label='Validation Loss', color='r')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('CNN Training Loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "        print(\"CNN Training Complete!\")\n",
        "\n",
        "        return loss_history, val_history\n",
        "\n",
        "\n",
        "    def train_val(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            imgs, labels = next(iter(self.dataloader.test_loader))\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = self(imgs, predict=True)\n",
        "            loss = self.weighted_loss(outputs, labels)\n",
        "        return loss\n",
        "\n",
        "    def save_model(self, file_path=\"cnn_model.pth\"):\n",
        "\n",
        "        del self.output_layer\n",
        "\n",
        "        torch.save(self.state_dict(), file_path)\n",
        "        print(f\"Model saved to {file_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "f5f6YaXs9Qhw"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "class PKAN_Data(Dataset):\n",
        "\n",
        "    def __init__(self, data_loader, train=True):\n",
        "        self.data_loader = data_loader\n",
        "        self.smiles = data_loader.train_smiles if train else data_loader.test_smiles\n",
        "        self.encoder = self.load_encoder()\n",
        "        data = self.generate_encoding_set(train)\n",
        "        del self.encoder # free up GPU resources\n",
        "        self.X = [copy.copy(x) for x in data['X']]\n",
        "        self.y = [copy.copy(y) for y in data['y']]\n",
        "\n",
        "        # Compute molecular weights for all SMILES in dataset\n",
        "        self.molecular_weights = self.compute_molecular_weights()\n",
        "\n",
        "    def compute_molecular_weights(self):\n",
        "        \"\"\"Computes molecular weights for all SMILES strings in dataset.\"\"\"\n",
        "        mol_weights = []\n",
        "        for smi in self.smiles:\n",
        "            mol = Chem.MolFromSmiles(smi)\n",
        "            if mol:\n",
        "                mw = Descriptors.MolWt(mol)  # Compute molecular weight\n",
        "                mol_weights.append(mw)\n",
        "            else:\n",
        "                print(f\"Invalid SMILES: {smi}\")  # Debugging output\n",
        "                mol_weights.append(0.0)  # Assign a default valid value (e.g., 0)\n",
        "        return torch.tensor(mol_weights, dtype=torch.float32, device=device)\n",
        "\n",
        "\n",
        "    def load_encoder(self, path='cnn_model.pth', input_dim=300):\n",
        "        model = CNN(self.data_loader, input_dim)\n",
        "        # strict=False allows us to use the model with the last layer dropped\n",
        "        model.load_state_dict(torch.load(path, map_location=device, weights_only=True), strict=False)\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        return model\n",
        "\n",
        "    def generate_encoding_set(self, train=True):\n",
        "        data = {'X': [], 'y': []}\n",
        "\n",
        "        loader = self.data_loader.train_loader if train else self.data_loader.test_loader\n",
        "        encodings = []\n",
        "        labels = []\n",
        "        for img, label in loader:\n",
        "            img = img.to(device)\n",
        "            encodings.append(self.encoder(img))\n",
        "            labels.append(label)\n",
        "\n",
        "        for i, e in enumerate(encodings):\n",
        "            for j in range(e.shape[0]):\n",
        "                data['X'].append(e[j])\n",
        "                data['y'].append(labels[i][j])\n",
        "        return data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx], self.molecular_weights[idx]\n",
        "\n",
        "\n",
        "class KANLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, num_kernels=10):\n",
        "\n",
        "        super(KANLayer, self).__init__()\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.num_kernels = num_kernels\n",
        "\n",
        "        self.weights = nn.Parameter(torch.randn(self.output_dim, self.num_kernels))\n",
        "        self.bias = nn.Parameter(torch.zeros(self.output_dim))\n",
        "\n",
        "        self.centers = nn.Parameter(torch.linspace(-1, 1, self.num_kernels))\n",
        "        self.widths = nn.Parameter(torch.ones(self.num_kernels) * 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        kernels = torch.exp(-((x.unsqueeze(-1) - self.centers) ** 2) / (2 * self.widths ** 2))\n",
        "        activation = torch.sum(torch.matmul(kernels, self.weights.T), dim=-1)  + self.bias\n",
        "\n",
        "        return activation\n",
        "\n",
        "class PKAN(nn.Module):\n",
        "\n",
        "    def __init__(self, kan_layer, train_data, test_data, feature_vec_size=64):\n",
        "        super(PKAN, self).__init__()\n",
        "\n",
        "        self.train_loader = DataLoader(train_data, batch_size=128, shuffle=True)\n",
        "        self.test_loader = DataLoader(test_data, batch_size=128, shuffle=True)\n",
        "\n",
        "        self.KAN_layer = kan_layer\n",
        "\n",
        "        self.fc_pipeline = nn.Sequential(\n",
        "            nn.Linear(feature_vec_size, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),  # Dropout after activation\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 64),\n",
        "            self.KAN_layer,\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),  # Slightly lower dropout for later layers\n",
        "            nn.Linear(32, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc_pipeline(x)\n",
        "        return x\n",
        "\n",
        "    def loss(self, pred, label, mol_weights, factor=0.1): # change when implementing physics loss\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "        base_loss = criterion(pred, label)\n",
        "        phys_loss = self.physics_loss(pred, mol_weights)\n",
        "        return base_loss + factor * phys_loss\n",
        "\n",
        "    def physics_loss(self, pred, mol_weights):\n",
        "        phys_loss = 0  # Initialize physics loss\n",
        "\n",
        "        # 1. Positivity Constraint (Ensure a and b are non-negative)\n",
        "        phys_loss += torch.mean(F.relu(-pred[:, 0]))  # Ensure a >= 0\n",
        "        phys_loss += torch.mean(F.relu(-pred[:, 1]))  # Ensure b >= 0\n",
        "\n",
        "        # 2. Approximate Physical Relationship\n",
        "        c = 0.1  # Empirical constant\n",
        "        phys_loss += torch.mean(F.relu(pred[:, 1] - c * (torch.abs(pred[:, 0]) ** (1/3))))  # Avoid negative roots\n",
        "\n",
        "        # 3. Enforce Monotonicity of b with Molecular Weight\n",
        "        sorted_indices = mol_weights.argsort()\n",
        "        sorted_b = pred[:, 1][sorted_indices]\n",
        "        sorted_molecular_weights = mol_weights[sorted_indices]\n",
        "\n",
        "        diffs = sorted_b[1:] - sorted_b[:-1]  # b_{i+1} - b_i\n",
        "        mw_diffs = sorted_molecular_weights[1:] - sorted_molecular_weights[:-1]  # M_{i+1} - M_i\n",
        "\n",
        "        valid_mask = mw_diffs > 1e-6  # Avoid division by zero or indexing errors\n",
        "        if valid_mask.any():  # Check if valid values exist\n",
        "            phys_loss += torch.mean(F.relu(-diffs[valid_mask]))\n",
        "\n",
        "        return phys_loss\n",
        "\n",
        "    def train_pkan(self, epochs=100, learning_rate=1e-4, patience=10, min_delta=0.001):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
        "\n",
        "        self.to(device)  # Move model to GPU if available\n",
        "        loss_history = []\n",
        "        val_history = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_weights = None\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            self.train()\n",
        "            running_loss = 0.0\n",
        "            running_val = 0.0\n",
        "\n",
        "            for inputs, labels, mol_weights in self.train_loader:\n",
        "                inputs, labels, mol_weights = inputs.to(device), labels.to(device), mol_weights.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                outputs = self(inputs)\n",
        "                loss = self.loss(outputs, labels, mol_weights)\n",
        "\n",
        "                loss.backward()\n",
        "                torch.nn.utils.clip_grad_norm_(self.parameters(), max_norm=1.0)  # Clip gradients\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                loss_history.append(loss.item())\n",
        "\n",
        "                val_loss = self.train_val()\n",
        "                running_val += val_loss.item()\n",
        "                val_history.append(val_loss.item())\n",
        "\n",
        "            avg_val_loss = running_val / len(self.test_loader)\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            print(f\"Epoch [{epoch+1}/{epochs}] Loss: {running_loss / len(self.train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "            print(f\"\\tValidation Loss: {running_val / len(self.test_loader):.4f}\")\n",
        "\n",
        "               # Early Stopping Logic\n",
        "            if avg_val_loss < best_val_loss - min_delta:\n",
        "                best_val_loss = avg_val_loss\n",
        "                best_model_weights = self.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping triggered after {epoch + 1} epochs!\")\n",
        "                break\n",
        "\n",
        "        # Restore best model before returning\n",
        "        if best_model_weights:\n",
        "            self.load_state_dict(best_model_weights)\n",
        "            print(\"Restored best model weights.\")\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(loss_history)\n",
        "        plt.plot(val_history, c='r')\n",
        "        plt.xlabel('Iterations')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.title('PKAN Training Loss')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"PKAN Training Complete!\")\n",
        "\n",
        "        return loss_history, val_history\n",
        "\n",
        "    def train_val(self):\n",
        "        self.eval()\n",
        "        with torch.no_grad():\n",
        "            imgs, labels, mol_weights = next(iter(self.test_loader))\n",
        "            imgs, labels, mol_weights = imgs.to(device), labels.to(device), mol_weights.to(device)\n",
        "\n",
        "            outputs = self(imgs)\n",
        "            loss = self.loss(outputs, labels, mol_weights)\n",
        "        self.train()\n",
        "        return loss\n",
        "\n",
        "    def validate_pkan(self, unscale_loader):\n",
        "        self.eval()  # Set model to evaluation mode\n",
        "        total_loss = 0.0\n",
        "        all_outputs = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():  # Disable gradient computation\n",
        "            for data in self.test_loader:\n",
        "                inputs, labels, mol_weights = data\n",
        "                inputs, labels, mol_weights = inputs.to(device), labels.to(device), mol_weights.to(device)\n",
        "\n",
        "                outputs = self(inputs)  # Forward pass through PKAN\n",
        "                loss = self.loss(outputs, labels, mol_weights)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                all_outputs.append(outputs.cpu().numpy())\n",
        "                all_labels.append(labels.cpu().numpy())\n",
        "\n",
        "        avg_loss = total_loss / len(self.test_loader)\n",
        "        print(f\"Validation Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        # Convert lists to numpy arrays for further evaluation\n",
        "        all_outputs = np.concatenate(all_outputs, axis=0)\n",
        "        all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "        # Unscale predictions and labels\n",
        "\n",
        "        # fix this, dataloader issues, scalers are not shared between dataset and dataloader\n",
        "        unscaled_outputs = unscale_loader.inverse_transform(torch.tensor(all_outputs))\n",
        "        unscaled_labels = unscale_loader.inverse_transform(torch.tensor(all_labels))\n",
        "\n",
        "        # Compute evaluation metrics\n",
        "        mae = np.mean(np.abs(unscaled_outputs - unscaled_labels), axis=0)\n",
        "        mse = np.mean((unscaled_outputs - unscaled_labels) ** 2, axis=0)\n",
        "\n",
        "        print(f\"Mean Absolute Error (MAE): a={mae[0]:.4f}, b={mae[1]:.4f}\")\n",
        "        print(f\"Mean Squared Error (MSE): a={mse[0]:.4f}, b={mse[1]:.4f}\")\n",
        "\n",
        "        return avg_loss, mae, mse\n",
        "\n",
        "    def save_model(self, file_path=\"pkan_model.pth\"):\n",
        "        torch.save(self.state_dict(), file_path)\n",
        "        print(f\"Model saved to {file_path}\")\n",
        "\n",
        "# implement physics loss, replace L1.\n",
        "# figure out if we use trend loss\n",
        "# consider other physical constraints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AcItTobw9YUj",
        "outputId": "273afcc6-76d1-4ac7-9420-1ac93f98133d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[14:44:27] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'CNN' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m test_data \u001b[38;5;241m=\u001b[39m EOS_Dataset(scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m eos_dataloader \u001b[38;5;241m=\u001b[39m EOS_Dataloader(train_data, test_data)\n\u001b[1;32m----> 6\u001b[0m cnn \u001b[38;5;241m=\u001b[39m CNN(eos_dataloader, \u001b[38;5;241m300\u001b[39m)\n\u001b[0;32m      8\u001b[0m cnn\u001b[38;5;241m.\u001b[39mtrain_model()\n\u001b[0;32m     10\u001b[0m cnn\u001b[38;5;241m.\u001b[39msave_model()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'CNN' is not defined"
          ]
        }
      ],
      "source": [
        "train_data = EOS_Dataset(scale=True, train=True)\n",
        "test_data = EOS_Dataset(scale=True, train=False)\n",
        "\n",
        "eos_dataloader = EOS_Dataloader(train_data, test_data)\n",
        "\n",
        "cnn = CNN(eos_dataloader, 300)\n",
        "\n",
        "cnn.train_model()\n",
        "\n",
        "cnn.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RcF0lLmO9ZLu",
        "outputId": "3f2605db-3405-488c-8c3d-b4cfd1ba63ab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[13:59:33] WARNING: not removing hydrogen atom without neighbors\n",
            "[13:59:43] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/100] Loss: 1.3216 | LR: 0.000100\n",
            "\tValidation Loss: 2.0538\n",
            "Epoch [2/100] Loss: 1.1871 | LR: 0.000100\n",
            "\tValidation Loss: 1.8866\n",
            "Epoch [3/100] Loss: 1.1343 | LR: 0.000100\n",
            "\tValidation Loss: 1.7300\n",
            "Epoch [4/100] Loss: 1.0940 | LR: 0.000100\n",
            "\tValidation Loss: 1.5830\n",
            "Epoch [5/100] Loss: 1.0277 | LR: 0.000100\n",
            "\tValidation Loss: 1.4450\n",
            "Epoch [6/100] Loss: 0.8913 | LR: 0.000100\n",
            "\tValidation Loss: 1.3215\n",
            "Epoch [7/100] Loss: 0.8501 | LR: 0.000100\n",
            "\tValidation Loss: 1.2127\n",
            "Epoch [8/100] Loss: 0.8927 | LR: 0.000100\n",
            "\tValidation Loss: 1.1139\n",
            "Epoch [9/100] Loss: 0.7655 | LR: 0.000100\n",
            "\tValidation Loss: 1.0266\n",
            "Epoch [10/100] Loss: 0.6938 | LR: 0.000100\n",
            "\tValidation Loss: 0.9511\n",
            "Epoch [11/100] Loss: 0.7231 | LR: 0.000100\n",
            "\tValidation Loss: 0.8931\n",
            "Epoch [12/100] Loss: 0.6334 | LR: 0.000100\n",
            "\tValidation Loss: 0.8509\n",
            "Epoch [13/100] Loss: 0.7117 | LR: 0.000100\n",
            "\tValidation Loss: 0.8167\n",
            "Epoch [14/100] Loss: 0.6308 | LR: 0.000100\n",
            "\tValidation Loss: 0.7895\n",
            "Epoch [15/100] Loss: 0.5870 | LR: 0.000100\n",
            "\tValidation Loss: 0.7673\n",
            "Epoch [16/100] Loss: 0.5819 | LR: 0.000100\n",
            "\tValidation Loss: 0.7480\n",
            "Epoch [17/100] Loss: 0.6749 | LR: 0.000100\n",
            "\tValidation Loss: 0.7317\n",
            "Epoch [18/100] Loss: 0.5604 | LR: 0.000100\n",
            "\tValidation Loss: 0.7215\n",
            "Epoch [19/100] Loss: 0.5290 | LR: 0.000100\n",
            "\tValidation Loss: 0.7133\n",
            "Epoch [20/100] Loss: 0.5798 | LR: 0.000100\n",
            "\tValidation Loss: 0.7159\n",
            "Epoch [21/100] Loss: 0.4497 | LR: 0.000100\n",
            "\tValidation Loss: 0.7222\n",
            "Epoch [22/100] Loss: 0.5551 | LR: 0.000100\n",
            "\tValidation Loss: 0.7279\n",
            "Epoch [23/100] Loss: 0.5354 | LR: 0.000100\n",
            "\tValidation Loss: 0.7327\n",
            "Epoch [24/100] Loss: 0.4934 | LR: 0.000100\n",
            "\tValidation Loss: 0.7369\n",
            "Epoch [25/100] Loss: 0.5117 | LR: 0.000050\n",
            "\tValidation Loss: 0.7403\n",
            "Epoch [26/100] Loss: 0.5230 | LR: 0.000050\n",
            "\tValidation Loss: 0.7412\n",
            "Epoch [27/100] Loss: 0.4858 | LR: 0.000050\n",
            "\tValidation Loss: 0.7408\n",
            "Epoch [28/100] Loss: 0.5032 | LR: 0.000050\n",
            "\tValidation Loss: 0.7405\n",
            "Epoch [29/100] Loss: 0.4856 | LR: 0.000050\n",
            "\tValidation Loss: 0.7400\n",
            "Early stopping triggered after 29 epochs!\n",
            "Restored best model weights.\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PKAN Training Complete!\n",
            "Validation Loss: 0.3700\n",
            "Mean Absolute Error (MAE): a=10.4278, b=0.0550\n",
            "Mean Squared Error (MSE): a=168.1015, b=0.0091\n",
            "Model saved to pkan_model.pth\n"
          ]
        }
      ],
      "source": [
        "train_data = EOS_Dataset(scale=True, train=True)\n",
        "test_data = EOS_Dataset(scale=True, train=False)\n",
        "\n",
        "eos_dataloader = EOS_Dataloader(train_data, test_data)\n",
        "\n",
        "pkan_train_data = PKAN_Data(eos_dataloader)\n",
        "pkan_test_data = PKAN_Data(eos_dataloader, False)\n",
        "\n",
        "kan_layer = KANLayer(64, 64)\n",
        "\n",
        "pkan = PKAN(kan_layer, pkan_train_data, pkan_test_data)\n",
        "\n",
        "pkan.train_pkan()\n",
        "\n",
        "pkan.validate_pkan(test_data)\n",
        "\n",
        "pkan.save_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class Evolved_CNN(nn.Module):\n",
        "\n",
        "    def __init__(self, dataloader, layers, fc_size):\n",
        "        super(Evolved_CNN, self).__init__()\n",
        "\n",
        "        self.dataloader = dataloader\n",
        "\n",
        "        self.layers = layers\n",
        "\n",
        "        self.output_layer = nn.Linear(fc_size, 2)\n",
        "\n",
        "        self._initialize_weights()\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self, x, predict=False):\n",
        "        x = self.layers(x)\n",
        "        if predict:\n",
        "            x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    def weighted_loss(self, outputs, labels):\n",
        "        criterion = nn.SmoothL1Loss()\n",
        "        loss = criterion(outputs, labels)\n",
        "        weight = torch.tensor([1.0, 80], device=device)  # Adjust if needed\n",
        "        return (loss * weight).mean()\n",
        "\n",
        "    def train_model(self, epochs=100, learning_rate=0.0001, patience=10, min_delta=0.001):\n",
        "        optimizer = optim.AdamW(self.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5)\n",
        "\n",
        "        self.to(device)  # Move the model to GPU if available\n",
        "\n",
        "        loss_history = []\n",
        "        val_history = []\n",
        "\n",
        "        best_val_loss = float('inf')\n",
        "        epochs_no_improve = 0\n",
        "        best_model_weights = None\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            running_loss = 0.0\n",
        "            running_val = 0.0\n",
        "\n",
        "            for data in self.dataloader.train_loader:\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(inputs, predict=True)\n",
        "                loss = self.weighted_loss(outputs, labels)\n",
        "                loss_history.append(loss.item())\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "\n",
        "                val_loss = self.train_val()\n",
        "                val_history.append(val_loss.item())\n",
        "                running_val += val_loss.item()\n",
        "\n",
        "            avg_val_loss = running_val / len(self.dataloader.test_loader)\n",
        "            scheduler.step(avg_val_loss)\n",
        "\n",
        "            # Early Stopping Logic\n",
        "            if avg_val_loss < best_val_loss - min_delta:\n",
        "                best_val_loss = avg_val_loss\n",
        "                best_model_weights = self.state_dict()\n",
        "                epochs_no_improve = 0\n",
        "            else:\n",
        "                epochs_no_improve += 1\n",
        "\n",
        "            if epochs_no_improve >= patience:\n",
        "                break\n",
        "\n",
        "        # Restore best model before returning\n",
        "        if best_model_weights:\n",
        "            self.load_state_dict(best_model_weights)\n",
        "\n",
        "        return loss_history, val_history\n",
        "\n",
        "\n",
        "    def train_val(self):\n",
        "\n",
        "        with torch.no_grad():\n",
        "            imgs, labels = next(iter(self.dataloader.test_loader))\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "\n",
        "            outputs = self(imgs, predict=True)\n",
        "            loss = self.weighted_loss(outputs, labels)\n",
        "        return loss\n",
        "\n",
        "    def save_model(self, file_path=\"cnn_model.pth\"):\n",
        "\n",
        "        del self.output_layer\n",
        "\n",
        "        torch.save(self.state_dict(), file_path)\n",
        "        print(f\"Model saved to {file_path}\")\n",
        "\n",
        "class CNN_GA():\n",
        "\n",
        "    def __init__(self):\n",
        "        self.NUM_CONV_LAYERS = [2, 3, 4]  # Number of convolutional layers\n",
        "        self.NUM_FILTERS = [32, 64, 128, 256]  # Filters per layer\n",
        "        self.KERNEL_SIZES = [3, 5]  # Kernel sizes\n",
        "        self.FC_SIZES = [64, 128, 256]  # Fully connected layer size\n",
        "        self.DROPOUT_RATES = [0.1, 0.2, 0.3]  # Dropout rates\n",
        "\n",
        "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
        "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
        "        self.toolbox = base.Toolbox()\n",
        "        self.toolbox.register(\"num_conv\", random.choice, self.NUM_CONV_LAYERS)\n",
        "        self.toolbox.register(\"filters\", random.choices, self.NUM_FILTERS, k=4)  # Max 4 layers\n",
        "        self.toolbox.register(\"kernel_sizes\", random.choices, self.KERNEL_SIZES, k=4)\n",
        "        self.toolbox.register(\"fc_size\", random.choice, self.FC_SIZES)\n",
        "        self.toolbox.register(\"dropout\", random.choice, self.DROPOUT_RATES)\n",
        "        self.toolbox.register(\"individual\", tools.initCycle, creator.Individual, \n",
        "                 (self.toolbox.num_conv, self.toolbox.filters, self.toolbox.kernel_sizes, self.toolbox.fc_size, self.toolbox.dropout), n=1)\n",
        "\n",
        "        # Population\n",
        "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
        "\n",
        "        # Register genetic operators\n",
        "        self.toolbox.register(\"evaluate\", self.evaluate)\n",
        "        self.toolbox.register(\"mate\", tools.cxTwoPoint)  # Crossover\n",
        "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3) # Selection\n",
        "\n",
        "        self.toolbox.register(\"mutate\", self.custom_mutate)\n",
        "\n",
        "\n",
        "        return\n",
        "    \n",
        "    def custom_mutate(self, individual):\n",
        "        num_conv = individual[0]\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            individual[0] = random.choice(self.NUM_CONV_LAYERS)\n",
        "            num_conv = individual[0]\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            individual[1:num_conv+1] = random.choices(self.NUM_FILTERS, k=num_conv)\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            individual[num_conv+1:2*num_conv+1] = random.choices(self.KERNEL_SIZES, k=num_conv)\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            individual[-2] = random.choice(self.FC_SIZES)\n",
        "\n",
        "        if random.random() < 0.2:\n",
        "            individual[-1] = random.choice(self.DROPOUT_RATES)\n",
        "\n",
        "        return (individual,)\n",
        "\n",
        "    \n",
        "    def build_cnn(self, individual):\n",
        "        num_conv = individual[0]\n",
        "        filters = individual[1:num_conv+1]\n",
        "        kernel_sizes = individual[num_conv+1:2*num_conv+1]\n",
        "        fc_size = individual[-2]\n",
        "        dropout_rate = individual[-1]\n",
        "\n",
        "        print(f\"num_conv: {num_conv}\")\n",
        "        print(f\"filters: {filters}\")\n",
        "        print(f\"kernel_sizes: {kernel_sizes}\")   \n",
        "\n",
        "        layers = []\n",
        "        in_channels = 3  # RGB images\n",
        "\n",
        "        for i in range(num_conv):\n",
        "            layers.append(nn.Conv2d(in_channels, filters[i], kernel_size=kernel_sizes[i], padding=1))\n",
        "            layers.append(nn.ReLU())\n",
        "            layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "            in_channels = filters[i]\n",
        "\n",
        "        # Get output feature size for FC layer\n",
        "        dummy_input = torch.randn(1, 3, 300, 300)\n",
        "        conv_out = nn.Sequential(*layers)(dummy_input)\n",
        "        out_features = conv_out.view(-1).shape[0]  # Flatten and count features\n",
        "\n",
        "        layers.append(nn.Flatten())\n",
        "        layers.append(nn.Linear(out_features, fc_size))\n",
        "        layers.append(nn.ReLU())\n",
        "        layers.append(nn.Dropout(dropout_rate))\n",
        "        layers.append(nn.Linear(fc_size, 64))\n",
        "        layers.append(nn.ReLU())\n",
        "\n",
        "        CNN = Evolved_CNN(eos_dataloader, nn.Sequential(*layers), fc_size)\n",
        "        return CNN\n",
        "\n",
        "    \n",
        "    def evaluate(self, individual):\n",
        "        cnn = self.build_cnn(individual)\n",
        "        t_loss, v_loss = cnn.train_model(epochs=50, learning_rate=0.0001, patience=10, min_delta=0.001)\n",
        "        return (v_loss,) # deap requires a tuple\n",
        "    \n",
        "    def run_ga(self):\n",
        "        pop = self.toolbox.population(n=10)  # Population size 10\n",
        "        hof = tools.HallOfFame(1)  # Store the best individual\n",
        "        stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
        "        stats.register(\"min\", np.min)\n",
        "        stats.register(\"avg\", np.mean)\n",
        "    \n",
        "        algorithms.eaSimple(pop, self.toolbox, cxpb=0.5, mutpb=0.2, ngen=20,  # 20 generations\n",
        "                            stats=stats, halloffame=hof, verbose=True)\n",
        "        \n",
        "        print(\"Best CNN found:\", hof[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_conv: 3\n",
            "filters: [[32, 128, 32, 32], [5, 3, 3, 5], 64]\n",
            "kernel_sizes: [0.1]\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "unsupported operand type(s) for %: 'list' and 'int'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m genetic_cnn_search \u001b[38;5;241m=\u001b[39m CNN_GA()\n\u001b[1;32m----> 3\u001b[0m genetic_cnn_search\u001b[38;5;241m.\u001b[39mrun_ga()\n",
            "Cell \u001b[1;32mIn[30], line 208\u001b[0m, in \u001b[0;36mCNN_GA.run_ga\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    205\u001b[0m stats\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmin)\n\u001b[0;32m    206\u001b[0m stats\u001b[38;5;241m.\u001b[39mregister(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean)\n\u001b[1;32m--> 208\u001b[0m algorithms\u001b[38;5;241m.\u001b[39meaSimple(pop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbox, cxpb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, mutpb\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, ngen\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m,  \u001b[38;5;66;03m# 20 generations\u001b[39;00m\n\u001b[0;32m    209\u001b[0m                     stats\u001b[38;5;241m=\u001b[39mstats, halloffame\u001b[38;5;241m=\u001b[39mhof, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest CNN found:\u001b[39m\u001b[38;5;124m\"\u001b[39m, hof[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[1;32mc:\\Users\\karim\\anaconda3\\envs\\eos\\Lib\\site-packages\\deap\\algorithms.py:151\u001b[0m, in \u001b[0;36meaSimple\u001b[1;34m(population, toolbox, cxpb, mutpb, ngen, stats, halloffame, verbose)\u001b[0m\n\u001b[0;32m    149\u001b[0m invalid_ind \u001b[38;5;241m=\u001b[39m [ind \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m population \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalid]\n\u001b[0;32m    150\u001b[0m fitnesses \u001b[38;5;241m=\u001b[39m toolbox\u001b[38;5;241m.\u001b[39mmap(toolbox\u001b[38;5;241m.\u001b[39mevaluate, invalid_ind)\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind, fit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(invalid_ind, fitnesses):\n\u001b[0;32m    152\u001b[0m     ind\u001b[38;5;241m.\u001b[39mfitness\u001b[38;5;241m.\u001b[39mvalues \u001b[38;5;241m=\u001b[39m fit\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m halloffame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "Cell \u001b[1;32mIn[30], line 197\u001b[0m, in \u001b[0;36mCNN_GA.evaluate\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mevaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, individual):\n\u001b[1;32m--> 197\u001b[0m     cnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_cnn(individual)\n\u001b[0;32m    198\u001b[0m     t_loss, v_loss \u001b[38;5;241m=\u001b[39m cnn\u001b[38;5;241m.\u001b[39mtrain_model(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, min_delta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m    199\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (v_loss,)\n",
            "Cell \u001b[1;32mIn[30], line 175\u001b[0m, in \u001b[0;36mCNN_GA.build_cnn\u001b[1;34m(self, individual)\u001b[0m\n\u001b[0;32m    172\u001b[0m in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# RGB images\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_conv):\n\u001b[1;32m--> 175\u001b[0m     layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, filters[i], kernel_size\u001b[38;5;241m=\u001b[39mkernel_sizes[i], padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    176\u001b[0m     layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mReLU())\n\u001b[0;32m    177\u001b[0m     layers\u001b[38;5;241m.\u001b[39mappend(nn\u001b[38;5;241m.\u001b[39mMaxPool2d(kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\karim\\anaconda3\\envs\\eos\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:521\u001b[0m, in \u001b[0;36mConv2d.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    519\u001b[0m padding_ \u001b[38;5;241m=\u001b[39m padding \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(padding, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m _pair(padding)\n\u001b[0;32m    520\u001b[0m dilation_ \u001b[38;5;241m=\u001b[39m _pair(dilation)\n\u001b[1;32m--> 521\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    522\u001b[0m     in_channels,\n\u001b[0;32m    523\u001b[0m     out_channels,\n\u001b[0;32m    524\u001b[0m     kernel_size_,\n\u001b[0;32m    525\u001b[0m     stride_,\n\u001b[0;32m    526\u001b[0m     padding_,\n\u001b[0;32m    527\u001b[0m     dilation_,\n\u001b[0;32m    528\u001b[0m     \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    529\u001b[0m     _pair(\u001b[38;5;241m0\u001b[39m),\n\u001b[0;32m    530\u001b[0m     groups,\n\u001b[0;32m    531\u001b[0m     bias,\n\u001b[0;32m    532\u001b[0m     padding_mode,\n\u001b[0;32m    533\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfactory_kwargs,\n\u001b[0;32m    534\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\karim\\anaconda3\\envs\\eos\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:108\u001b[0m, in \u001b[0;36m_ConvNd.__init__\u001b[1;34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, transposed, output_padding, groups, bias, padding_mode, device, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m in_channels \u001b[38;5;241m%\u001b[39m groups \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min_channels must be divisible by groups\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_channels \u001b[38;5;241m%\u001b[39m groups \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_channels must be divisible by groups\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    110\u001b[0m valid_padding_strings \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n",
            "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for %: 'list' and 'int'"
          ]
        }
      ],
      "source": [
        "genetic_cnn_search = CNN_GA()\n",
        "\n",
        "genetic_cnn_search.run_ga()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "eos",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
