{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PrqCQDDqah2",
        "outputId": "21dd0c4f-60b5-4d28-ecf5-318e46e0ef57"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m49.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "metadata": {
        "id": "sAmXUfIsqIXZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CkhATIO1tMb6"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_url = 'https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/train_data.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/test_data.csv'"
      ],
      "metadata": {
        "id": "xieT3LVGqUg5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "S55-Zbk5p4jQ",
        "outputId": "dfe7eda6-fa22-4df8-8140-296f8210dec2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "class MoleculeVisualizer():\n",
        "    def visualize_molecule_2D(self,smiles):\n",
        "        \"\"\"\n",
        "        Generates a 2D image of the molecule from its SMILES representation.\n",
        "        \"\"\"\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES string.\")\n",
        "            return\n",
        "\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        return img\n",
        "\n",
        "visualizer = MoleculeVisualizer()\n",
        "visualizer.visualize_molecule_2D('CCO')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_url)\n",
        "test_data = pd.read_csv(test_url)\n",
        "\n",
        "X_cols = ['sci_name','name','cid','smile','Molecular Weight','LogP','TPSA','Rotatable Bonds','H Bond Donors','H Bond Acceptors','Aromatic Rings','Num Rings','Atom Count','coulomb_matrix','embeddings']\n",
        "y_cols = ['a', 'b']\n",
        "\n",
        "X_train = train_data[X_cols]\n",
        "y_train = train_data[y_cols]\n",
        "X_test = test_data[X_cols]\n",
        "y_test = test_data[y_cols]\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOIzx9CHqi6a",
        "outputId": "2b141541-da3d-45a6-c522-fde1de71b169"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 15) (165, 2) (55, 15) (55, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = []\n",
        "test_imgs = []\n",
        "\n",
        "for smile in X_train['smile']:\n",
        "    img = MoleculeVisualizer().visualize_molecule_2D(smile)\n",
        "    train_imgs.append(np.array(img, dtype=np.float32))\n",
        "\n",
        "for smile in X_test['smile']:\n",
        "    img = MoleculeVisualizer().visualize_molecule_2D(smile)\n",
        "    test_imgs.append(np.array(img, dtype=np.float32))\n",
        "\n",
        "train_imgs = np.array(train_imgs)\n",
        "test_imgs = np.array(test_imgs)\n",
        "\n",
        "print(train_imgs.shape, test_imgs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRekeJ2q9T0",
        "outputId": "3fbbceb8-0268-42c5-fa3f-423ab5654a15"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[19:44:43] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 300, 300, 3) (55, 300, 300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EOSDataset(Dataset):\n",
        "\n",
        "  def __init__(self, imgs, y):\n",
        "    self.imgs = imgs\n",
        "    self.y = y.values.astype(np.float32)\n",
        "    self.transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.imgs[idx]\n",
        "    label = self.y[idx]\n",
        "\n",
        "    img = self.transform(img)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "  def transform(self, img):\n",
        "    return self.transform(img)"
      ],
      "metadata": {
        "id": "XzDal_4psKiB"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self, train_loader, test_loader):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(3, 32, kernel_size=7, padding=1)\n",
        "    self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=2)\n",
        "    self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "\n",
        "    # Batch Normalization\n",
        "    self.bn1 = nn.BatchNorm2d(32)\n",
        "    self.bn2 = nn.BatchNorm2d(64)\n",
        "    self.bn3 = nn.BatchNorm2d(128)\n",
        "\n",
        "    self.fc1 = nn.Linear(128 * 74 * 74, 128)\n",
        "    self.fc2 = nn.Linear(128, 64)\n",
        "    self.fc3 = nn.Linear(64, 2)\n",
        "\n",
        "    self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.train_loader = train_loader\n",
        "    self.test_loader = test_loader\n",
        "\n",
        "    # Dropout for regularization\n",
        "    self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "  # For training model on a and b and getting embedded vector for PKAN\n",
        "  def forward(self, x):\n",
        "    x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
        "    x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
        "    x = F.relu(self.bn3(self.conv3(x)))\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = self.dropout(x)  # Regularization\n",
        "    x = F.relu(self.fc2(x))\n",
        "    return x\n",
        "\n",
        "  # For training on a and b, not final output of model\n",
        "  def predict(self, x):\n",
        "    x = self.forward(x)\n",
        "    x = F.relu(self.fc3(x))\n",
        "    return x\n",
        "\n",
        "  def train(self, train_loader, epochs, learning_rate):\n",
        "    criterion = nn.MSELoss()\n",
        "    optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "\n",
        "    self.to(device)  # Move the model to the device (GPU if available)\n",
        "\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(train_loader, 0):\n",
        "            inputs, labels = data  # Get the inputs and labels from the data loader\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = self.predict(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, labels)  # Calculate the loss\n",
        "            loss_history.append(loss.item())\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update the model's parameters\n",
        "\n",
        "            running_loss += loss.item()  # Accumulate the loss for the epoch\n",
        "\n",
        "        # Print the average loss for the epoch\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {running_loss / len(train_loader):.4f}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(loss_history)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "\n",
        "    self.to(device)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "pcNW3gGirC8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EOSDataset(train_imgs, y_train)\n",
        "test_dataset = EOSDataset(test_imgs, y_test)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ],
      "metadata": {
        "id": "gME4l7FFtizn"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN(train_loader, test_loader)\n",
        "cnn.train(train_loader, epochs=10, learning_rate=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "AEO60xCvt0Zh",
        "outputId": "ac4b6b80-a472-4273-8d12-e9590fbded62"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 700928])\n",
            "torch.Size([32, 700928])\n",
            "torch.Size([32, 700928])\n",
            "torch.Size([32, 700928])\n",
            "torch.Size([32, 700928])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-56780c80a853>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-89-96db5913a98f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Calculate the loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backpropagation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Update the model's parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}