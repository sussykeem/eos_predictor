{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PrqCQDDqah2",
        "outputId": "7401d3ff-3855-4688-e17b-bdd59a258066"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Downloading rdkit-2024.9.5-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rdkit\n",
            "Successfully installed rdkit-2024.9.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import Draw\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "sAmXUfIsqIXZ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "id": "CkhATIO1tMb6",
        "outputId": "7c0c1e27-aaa6-4f2d-b97e-a8f00d1d07e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_url = 'https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/train_data.csv'\n",
        "test_url = 'https://raw.githubusercontent.com/sussykeem/eos_predictor/refs/heads/main/eos_dataset/test_data.csv'"
      ],
      "metadata": {
        "id": "xieT3LVGqUg5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "S55-Zbk5p4jQ",
        "outputId": "0ce2b980-ef90-4aee-cc2c-368036fe8bd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGB size=300x300>"
            ],
            "image/png": "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\n",
            "image/jpeg": "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\n"
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "class MoleculeVisualizer():\n",
        "    def visualize_molecule_2D(self,smiles):\n",
        "        \"\"\"\n",
        "        Generates a 2D image of the molecule from its SMILES representation.\n",
        "        \"\"\"\n",
        "        mol = Chem.MolFromSmiles(smiles)\n",
        "        if mol is None:\n",
        "            print(\"Invalid SMILES string.\")\n",
        "            return\n",
        "\n",
        "        img = Draw.MolToImage(mol, size=(300, 300))\n",
        "\n",
        "        return img\n",
        "\n",
        "visualizer = MoleculeVisualizer()\n",
        "visualizer.visualize_molecule_2D('CCO')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(train_url)\n",
        "test_data = pd.read_csv(test_url)\n",
        "\n",
        "X_cols = ['sci_name','name','cid','smile','Molecular Weight','LogP','TPSA','Rotatable Bonds','H Bond Donors','H Bond Acceptors','Aromatic Rings','Num Rings','Atom Count','coulomb_matrix','embeddings']\n",
        "y_cols = ['a', 'b']\n",
        "\n",
        "X_train = train_data[X_cols]\n",
        "y_train = train_data[y_cols]\n",
        "X_test = test_data[X_cols]\n",
        "y_test = test_data[y_cols]\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOIzx9CHqi6a",
        "outputId": "3d3747a3-5dbe-4239-9c4a-fb02198591db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 15) (165, 2) (55, 15) (55, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_mean = y_train['a'].mean()\n",
        "b_mean = y_train['b'].mean()\n",
        "\n",
        "diff = a_mean / b_mean\n",
        "print(diff)"
      ],
      "metadata": {
        "id": "p-BG6BLiHYch",
        "outputId": "073e0531-283e-4003-b614-707d64c6350d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "159.90314965096417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_imgs = []\n",
        "test_imgs = []\n",
        "\n",
        "for smile in X_train['smile']:\n",
        "    img = MoleculeVisualizer().visualize_molecule_2D(smile)\n",
        "    train_imgs.append(np.array(img, dtype=np.float32))\n",
        "\n",
        "for smile in X_test['smile']:\n",
        "    img = MoleculeVisualizer().visualize_molecule_2D(smile)\n",
        "    test_imgs.append(np.array(img, dtype=np.float32))\n",
        "\n",
        "train_imgs = np.array(train_imgs)\n",
        "test_imgs = np.array(test_imgs)\n",
        "\n",
        "print(train_imgs.shape, test_imgs.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRekeJ2q9T0",
        "outputId": "cff1b926-b36d-46a1-e0a8-ec59373d2d8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[21:28:26] WARNING: not removing hydrogen atom without neighbors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(165, 300, 300, 3) (55, 300, 300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class EOSDataset(Dataset):\n",
        "\n",
        "  def __init__(self, imgs, y, scale=True):\n",
        "    self.imgs = imgs\n",
        "    self.y = y.values.astype(np.float32)\n",
        "    self.transform = transforms.Compose([\n",
        "      transforms.ToTensor(),\n",
        "      transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "\n",
        "    # Separate scalers for a and b\n",
        "    self.scaler_a = StandardScaler()\n",
        "    self.scaler_b = StandardScaler()\n",
        "\n",
        "    # Fit scalers on the respective columns\n",
        "    if scale:\n",
        "      self.y[:, 0] = self.scaler_a.fit_transform(self.y[:, 0].reshape(-1, 1)).reshape(-1)\n",
        "      self.y[:, 1] = self.scaler_b.fit_transform(self.y[:, 1].reshape(-1, 1)).reshape(-1)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.imgs)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    img = self.imgs[idx]\n",
        "    label = self.y[idx]\n",
        "\n",
        "    img = self.transform(img)\n",
        "\n",
        "    return img, label\n",
        "\n",
        "  def transform(self, img):\n",
        "    return self.transform(img)\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "XzDal_4psKiB"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from re import M\n",
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self, train_dataset, test_dataset):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.cnn_pipeline = nn.Sequential(\n",
        "        nn.Conv2d(3, 32, kernel_size=7, padding=1),\n",
        "        nn.BatchNorm2d(32, affine=False),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "        nn.BatchNorm2d(64, affine=False),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "        nn.BatchNorm2d(128, affine=False),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    self.fc_pipeline = nn.Sequential(\n",
        "        nn.Linear(128 * 74 * 74, 128),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.3),\n",
        "        nn.Linear(128, 64),\n",
        "        nn.ReLU(),\n",
        "    )\n",
        "\n",
        "    self.output_layer = nn.Linear(64, 2)\n",
        "\n",
        "    self.train_dataset = train_dataset\n",
        "    self.test_dataset = test_dataset\n",
        "\n",
        "\n",
        "    self.train_loader = DataLoader(self.train_dataset, batch_size=32, shuffle=True)\n",
        "    self.test_loader = DataLoader(self.test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "    # self._initialize_weights()\n",
        "\n",
        "  def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
        "                nn.init.xavier_uniform_(m.weight)\n",
        "                if m.bias is not None:\n",
        "                    nn.init.zeros_(m.bias)\n",
        "\n",
        "  # For training model on a and b and getting embedded vector for PKAN\n",
        "  def forward(self, x, predict=False):\n",
        "    x = self.cnn_pipeline(x)\n",
        "    x = torch.flatten(x, 1)\n",
        "    x = self.fc_pipeline(x)\n",
        "    if predict:\n",
        "        x = self.output_layer(x)\n",
        "    return x\n",
        "\n",
        "  def unscale_predict(self, x, train=True):\n",
        "    if train:\n",
        "      scaler_a = self.train_dataset.scaler_a\n",
        "      scaler_b = self.train_dataset.scaler_b\n",
        "    else:\n",
        "      scaler_a = self.test_dataset.scaler_a\n",
        "      scaler_b = self.test_dataset.scaler_b\n",
        "\n",
        "    x[:, 0] = scaler_a.inverse_transform(x[:, 0].reshape(-1, 1)).reshape(-1)\n",
        "    x[:, 1] = scaler_b.inverse_transform(x[:, 1].reshape(-1, 1)).reshape(-1)\n",
        "    return x\n",
        "\n",
        "  def weighted_loss(self, outputs, labels):\n",
        "    criterion = nn.MSELoss()\n",
        "    loss = criterion(outputs, labels)\n",
        "    weight = torch.tensor([1.0, 160.0], device=device)  # Adjust if needed\n",
        "    return (loss * weight).mean()\n",
        "\n",
        "  def train(self, epochs, learning_rate, step_size, gamma):\n",
        "    optimizer = optim.Adam(self.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    self.to(device)  # Move the model to the device (GPU if available)\n",
        "\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        running_loss = 0.0\n",
        "        for i, data in enumerate(self.train_loader, 0):\n",
        "            inputs, labels = data  # Get the inputs and labels from the data loader\n",
        "            inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "            optimizer.zero_grad()  # Zero the parameter gradients\n",
        "            outputs = self(inputs, predict=True)  # Forward pass\n",
        "            loss = self.weighted_loss(outputs, labels)  # Calculate the loss\n",
        "            loss_history.append(loss.item())\n",
        "            loss.backward()  # Backpropagation\n",
        "            optimizer.step()  # Update the model's parameters\n",
        "\n",
        "            running_loss += loss.item()  # Accumulate the loss for the epoch\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Print the average loss for the epoch\n",
        "        print(f\"Epoch [{epoch + 1}/{epochs}] Loss: {running_loss / len(self.train_loader):.4f} | LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(loss_history)\n",
        "    plt.xlabel('Iterations')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "\n",
        "    self.to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "pcNW3gGirC8v"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = EOSDataset(train_imgs, y_train, False)\n",
        "test_dataset = EOSDataset(test_imgs, y_test, False)"
      ],
      "metadata": {
        "id": "gME4l7FFtizn"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnn = CNN(train_dataset, test_dataset)\n",
        "cnn.train(epochs=100, learning_rate=0.001, step_size=10, gamma=0.8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEO60xCvt0Zh",
        "outputId": "e9087ed6-6ecf-4619-d582-a2c046a5d53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100] Loss: 240789.8167 | LR: 0.001000\n",
            "Epoch [2/100] Loss: 26321.7070 | LR: 0.001000\n",
            "Epoch [3/100] Loss: 24457.1133 | LR: 0.001000\n",
            "Epoch [4/100] Loss: 13055.6518 | LR: 0.001000\n",
            "Epoch [5/100] Loss: 13600.1460 | LR: 0.001000\n",
            "Epoch [6/100] Loss: 9348.8351 | LR: 0.001000\n",
            "Epoch [7/100] Loss: 7421.2996 | LR: 0.001000\n",
            "Epoch [8/100] Loss: 7243.2845 | LR: 0.001000\n",
            "Epoch [9/100] Loss: 5066.4551 | LR: 0.001000\n",
            "Epoch [10/100] Loss: 4475.2389 | LR: 0.000800\n",
            "Epoch [11/100] Loss: 3936.0119 | LR: 0.000800\n",
            "Epoch [12/100] Loss: 3775.1149 | LR: 0.000800\n",
            "Epoch [13/100] Loss: 2770.0431 | LR: 0.000800\n",
            "Epoch [14/100] Loss: 2167.5567 | LR: 0.000800\n",
            "Epoch [15/100] Loss: 2344.3612 | LR: 0.000800\n",
            "Epoch [16/100] Loss: 2330.8068 | LR: 0.000800\n",
            "Epoch [17/100] Loss: 2664.1023 | LR: 0.000800\n",
            "Epoch [18/100] Loss: 1829.5967 | LR: 0.000800\n",
            "Epoch [19/100] Loss: 2365.8555 | LR: 0.000800\n",
            "Epoch [20/100] Loss: 2111.0424 | LR: 0.000640\n",
            "Epoch [21/100] Loss: 2536.9594 | LR: 0.000640\n",
            "Epoch [22/100] Loss: 2769.1367 | LR: 0.000640\n",
            "Epoch [23/100] Loss: 2206.2525 | LR: 0.000640\n",
            "Epoch [24/100] Loss: 1547.1750 | LR: 0.000640\n",
            "Epoch [25/100] Loss: 1809.0348 | LR: 0.000640\n",
            "Epoch [26/100] Loss: 1486.3495 | LR: 0.000640\n",
            "Epoch [27/100] Loss: 2075.2259 | LR: 0.000640\n",
            "Epoch [28/100] Loss: 1320.7240 | LR: 0.000640\n",
            "Epoch [29/100] Loss: 931.0753 | LR: 0.000640\n",
            "Epoch [30/100] Loss: 1468.8118 | LR: 0.000512\n",
            "Epoch [31/100] Loss: 1510.2258 | LR: 0.000512\n",
            "Epoch [32/100] Loss: 1258.7211 | LR: 0.000512\n",
            "Epoch [33/100] Loss: 922.6039 | LR: 0.000512\n",
            "Epoch [34/100] Loss: 1357.5679 | LR: 0.000512\n",
            "Epoch [35/100] Loss: 1210.8999 | LR: 0.000512\n",
            "Epoch [36/100] Loss: 1544.1201 | LR: 0.000512\n",
            "Epoch [37/100] Loss: 757.5478 | LR: 0.000512\n",
            "Epoch [38/100] Loss: 1133.8509 | LR: 0.000512\n",
            "Epoch [39/100] Loss: 1369.9174 | LR: 0.000512\n",
            "Epoch [40/100] Loss: 963.9663 | LR: 0.000410\n",
            "Epoch [41/100] Loss: 1023.4420 | LR: 0.000410\n",
            "Epoch [42/100] Loss: 2003.2352 | LR: 0.000410\n",
            "Epoch [43/100] Loss: 2524.4463 | LR: 0.000410\n",
            "Epoch [44/100] Loss: 1146.1207 | LR: 0.000410\n",
            "Epoch [45/100] Loss: 783.9893 | LR: 0.000410\n",
            "Epoch [46/100] Loss: 1256.9823 | LR: 0.000410\n",
            "Epoch [47/100] Loss: 1244.8544 | LR: 0.000410\n",
            "Epoch [48/100] Loss: 1393.0167 | LR: 0.000410\n",
            "Epoch [49/100] Loss: 1074.2717 | LR: 0.000410\n",
            "Epoch [50/100] Loss: 795.3392 | LR: 0.000328\n",
            "Epoch [51/100] Loss: 1172.8500 | LR: 0.000328\n",
            "Epoch [52/100] Loss: 898.0105 | LR: 0.000328\n",
            "Epoch [53/100] Loss: 1095.6626 | LR: 0.000328\n",
            "Epoch [54/100] Loss: 827.2784 | LR: 0.000328\n",
            "Epoch [55/100] Loss: 768.0487 | LR: 0.000328\n",
            "Epoch [56/100] Loss: 1092.5514 | LR: 0.000328\n",
            "Epoch [57/100] Loss: 776.7357 | LR: 0.000328\n",
            "Epoch [58/100] Loss: 590.9638 | LR: 0.000328\n",
            "Epoch [59/100] Loss: 2409.9271 | LR: 0.000328\n",
            "Epoch [60/100] Loss: 926.7738 | LR: 0.000262\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img, label = train_dataset.__getitem__(0)\n",
        "\n",
        "encoding = cnn.unscale_predict(cnn.predict(img.to(device).unsqueeze(0)))\n",
        "\n",
        "print(encoding)"
      ],
      "metadata": {
        "id": "7faaC4Dc7xt7",
        "outputId": "8f877a8b-143b-459c-db43-35f203026935",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-ff02d10ad462>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munscale_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-5fb37424efee>\u001b[0m in \u001b[0;36munscale_predict\u001b[0;34m(self, x, train)\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m         X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1053\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1055\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m                 raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m_asarray_with_order\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    837\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1149\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[0;31m# Wrap Numpy array again in a suitable tensor when done, to support e.g.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
          ]
        }
      ]
    }
  ]
}